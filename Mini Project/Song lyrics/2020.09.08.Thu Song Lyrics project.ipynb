{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Data 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 아래 링크에서 **Song Lyrics** data download\n",
    "- 저장된 파일 **압축 해제**한 후, 모든 ```txt``` 파일을 ```lyrics```폴더를 만들어 그 안에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  wget https://aiffelstaticprd.blob.core.windows.net/media/documents/song_lyrics.zip\n",
    "- unzip song_lyrics.zip -d ~/aiffel/lyricist/data/lyrics  #lyrics 폴더에 압축풀기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Data 읽어오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```glob``` 모듈을 사용하면 파일 읽엉는 작업 용이\n",
    "- ```glob``` 활용하여 모든 ```txt``` 파일 읽어온 후\n",
    "- ```raw_corpus``` 리스트에 문장 단위로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " ['The Cat in the Hat', 'By Dr. Seuss', 'The sun did not shine.', 'It was too wet to play.', 'So we sat in the house', 'All that cold cold wet day.', 'I sat there with Sally.', 'We sat there we two.', 'And I said How I wish']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import os\n",
    "\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel//lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))    # element 개수 = 데이터 크기 \n",
    "print(\"Examples:\\n\", raw_corpus[:9])    # 앞에서부터 10라인 화면 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Data 정제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```preprocess_settence()```함수 활용해서 데이터 정제\n",
    "- 지나치게 긴 문장은 다른 데이터들이 과도한 padding을 갖게 하므로 제거\n",
    "- 문장을 **토큰화** 했을 때 토큰 개수가 15개 넘어가면 자르기 권유"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> the sun d d d d d d a d d d d d <end>\n"
     ]
    }
   ],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()  \n",
    "    \n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)        # 패턴의 특수문자를 만나면 특수문자 양쪽에 공백을 추가\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)                  # 공백 패턴을 만나면 스페이스 1개로 치환\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)  # a-zA-Z?.!,¿ 패턴을 제외한 모든 문자(공백문자까지도)를 스페이스 1개로 치환\n",
    "    \n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    sentence = '<start> ' + sentence + ' <end>'      # 이전 스텝에서 본 것처럼 문장 앞뒤로 <start>와 <end>를 단어처럼 붙여 줍니다\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "print(preprocess_sentence(\"The @#$ SUN d d d d D d a243414#@$d d d d d  \"))   # 이 문장이 어떻게 필터링되는지 확인해 보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. 평가 데이터셋 분리\n",
    "- ```tokenize()```함수로 데이터를 tensor로 변환 후\n",
    "- ```sklearn```모듈의 ```train_test_split()```함수를 사용하여 훈련, 평가 데이터 분리\n",
    "- **단어장의 크기는 12,000 이상**으로 설정\n",
    "- **총 데이터의 20%**를 평가 데이터셋으로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> the cat in the hat <end>',\n",
       " '<start> by dr . seuss <end>',\n",
       " '<start> the sun did not shine . <end>',\n",
       " '<start> it was too wet to play . <end>',\n",
       " '<start> so we sat in the house <end>',\n",
       " '<start> all that cold cold wet day . <end>',\n",
       " '<start> i sat there with sally . <end>',\n",
       " '<start> we sat there we two . <end>',\n",
       " '<start> and i said how i wish <end>',\n",
       " '<start> we had something to do ! <end>']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    if len(sentence) == 0: continue\n",
    "        \n",
    "    corpus.append(preprocess_sentence(sentence))\n",
    "        \n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2   6 904 ...   0   0   0]\n",
      " [  2 122   1 ...   0   0   0]\n",
      " [  2   6 305 ...   0   0   0]\n",
      " ...\n",
      " [  2 675  27 ...   0   0   0]\n",
      " [  2 675  27 ...   0   0   0]\n",
      " [  2 675  27 ...   0   0   0]] <keras_preprocessing.text.Tokenizer object at 0x7f66a9252050>\n"
     ]
    }
   ],
   "source": [
    "def tokenize(corpus):\n",
    "    # 텐서플로우에서 제공하는 Tokenizer 패키지를 생성\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=1200,  # 전체 단어의 개수 \n",
    "        filters=' ',    # 별도로 전처리 로직을 추가할 수 있습니다. 이번에는 사용하지 않겠습니다.\n",
    "        oov_token=\"<unk>\"  # out-of-vocabulary, 사전에 없었던 단어는 어떤 토큰으로 대체할지\n",
    "    )\n",
    "    tokenizer.fit_on_texts(corpus)   # 우리가 구축한 corpus로부터 Tokenizer가 사전을 자동구축하게 됩니다.\n",
    "\n",
    "    # 이후 tokenizer를 활용하여 모델에 입력할 데이터셋을 구축하게 됩니다.\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   # tokenizer는 구축한 사전으로부터 corpus를 해석해 Tensor로 변환합니다.\n",
    "\n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게 맞추기 위한 padding  메소드를 제공합니다.\n",
    "    # maxlen의 디폴트값은 None입니다. 이 경우 corpus의 가장 긴 문장을 기준으로 시퀀스 길이가 맞춰집니다.\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')  \n",
    "\n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175986, 347)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = np.delete(tensor, np.s_[14:], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175986, 14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2,   6, 904, ...,   0,   0,   0],\n",
       "       [  2, 122,   1, ...,   0,   0,   0],\n",
       "       [  2,   6, 305, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  2, 675,  27, ..., 675,  27,   6],\n",
       "       [  2, 675,  27, ...,   0,   0,   0],\n",
       "       [  2, 675,  27, ...,   0,   0,   0]], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid = train_test_split(tensor, test_size=0.2, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140788, 14)\n",
      "(35198, 14)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train = x_train[:, :-1] \n",
    "dec_train = x_train[:, 1:]\n",
    "\n",
    "enc_val = x_valid[:, :-1]\n",
    "dec_val = x_valid[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140788, 13)\n",
      "(140788, 13)\n",
      "(35198, 13)\n",
      "(35198, 13)\n"
     ]
    }
   ],
   "source": [
    "print(enc_train.shape)\n",
    "print(dec_train.shape)\n",
    "\n",
    "print(enc_val.shape)\n",
    "print(dec_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. 인공지능 만들기\n",
    "- 모델의 Embedding Size & Hidden Size 조절\n",
    "- 10 Epoch 안에 ```val_loss```값을 **2.2**수준으로 줄이는 모델 설계\n",
    "- Loss는 제시된 Loss 함수 그대로 사용!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 13), (256, 13)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(enc_train)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(enc_train) // BATCH_SIZE\n",
    "\n",
    "VOCAB_SIZE = tokenizer.num_words + 1    # tokenizer가 구축한 단어사전 내 7000개와, 여기 포함되지 않은 0:<pad>를 포함하여 7001개\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 13), (256, 13)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset = tf.data.Dataset.from_tensor_slices((enc_val, dec_val)).shuffle(BUFFER_SIZE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(TextGenerator, self).__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        self.bn2a_1 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        \n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.bn2a_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        \n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 256\n",
    "hidden_size = 1024\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 13, 1201), dtype=float32, numpy=\n",
       "array([[[-6.1928446e-04,  4.9484993e-04, -5.6126277e-04, ...,\n",
       "         -7.2491291e-04, -2.2428794e-04,  2.2621317e-04],\n",
       "        [-1.4983560e-04,  6.2973663e-04, -9.5036725e-04, ...,\n",
       "         -1.4311346e-03, -4.8766451e-04,  8.3320704e-04],\n",
       "        [ 5.9212546e-04,  5.1433942e-04, -1.1341163e-03, ...,\n",
       "         -2.5185011e-03, -4.7088266e-05,  1.2627222e-03],\n",
       "        ...,\n",
       "        [ 1.6239014e-03, -1.6476064e-03, -3.9961352e-03, ...,\n",
       "         -1.1682006e-03, -2.5319663e-04,  1.5639492e-04],\n",
       "        [ 1.4218043e-03, -8.7633426e-04, -4.1384338e-03, ...,\n",
       "         -8.8077725e-04, -1.3841821e-04, -7.7168789e-04],\n",
       "        [ 1.9771541e-03, -6.6596369e-04, -4.7851796e-03, ...,\n",
       "         -1.2539623e-04, -2.9328893e-04, -1.0832996e-03]],\n",
       "\n",
       "       [[-6.1928446e-04,  4.9484993e-04, -5.6126277e-04, ...,\n",
       "         -7.2491291e-04, -2.2428794e-04,  2.2621317e-04],\n",
       "        [-4.4212784e-04,  1.7335743e-04, -1.0342548e-03, ...,\n",
       "         -1.1343705e-03,  1.2965140e-05,  2.9451685e-04],\n",
       "        [ 4.0722289e-04, -1.5399706e-05, -1.2639255e-03, ...,\n",
       "         -1.6116595e-03,  1.1940842e-05,  8.3293731e-04],\n",
       "        ...,\n",
       "        [ 1.9666282e-03, -1.8282725e-03,  1.5819131e-03, ...,\n",
       "          1.2980355e-04, -1.2780584e-03, -2.5405462e-03],\n",
       "        [ 1.1863250e-03, -1.8963810e-03,  8.2569837e-04, ...,\n",
       "          3.7106793e-04, -8.0999121e-04, -3.1500722e-03],\n",
       "        [ 4.9440673e-04, -2.1242015e-03,  8.3264247e-05, ...,\n",
       "          8.5848570e-04, -5.6767906e-04, -2.6221913e-03]],\n",
       "\n",
       "       [[-6.1928446e-04,  4.9484993e-04, -5.6126277e-04, ...,\n",
       "         -7.2491291e-04, -2.2428794e-04,  2.2621317e-04],\n",
       "        [-1.9128293e-04,  2.6732666e-04, -8.3568471e-04, ...,\n",
       "         -1.8319543e-03, -2.8048622e-04,  1.9356467e-04],\n",
       "        [ 2.5456384e-04, -8.2311640e-04, -1.1749292e-03, ...,\n",
       "         -1.8451983e-03, -4.0983108e-05, -1.1886808e-04],\n",
       "        ...,\n",
       "        [-2.1094102e-03,  5.5294260e-03, -1.9391492e-03, ...,\n",
       "          4.7400328e-03, -1.2464169e-03,  1.3384357e-03],\n",
       "        [-2.7100719e-03,  6.2102824e-03, -1.9311509e-03, ...,\n",
       "          5.5256300e-03, -1.5456845e-03,  1.2032791e-03],\n",
       "        [-3.2596961e-03,  6.7977323e-03, -1.9200966e-03, ...,\n",
       "          6.2271492e-03, -1.8073593e-03,  1.0326446e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-6.1928446e-04,  4.9484993e-04, -5.6126277e-04, ...,\n",
       "         -7.2491291e-04, -2.2428794e-04,  2.2621317e-04],\n",
       "        [-7.1098527e-04,  6.0720620e-04, -1.1396008e-03, ...,\n",
       "         -1.2574694e-03,  8.2613493e-05,  1.9904003e-04],\n",
       "        [-3.6263088e-04,  2.0950992e-04, -1.5004027e-03, ...,\n",
       "         -9.0324151e-04,  1.2089496e-04,  1.0629805e-04],\n",
       "        ...,\n",
       "        [ 3.3554118e-04,  2.1605878e-03, -2.3991482e-03, ...,\n",
       "          4.6778031e-04,  1.1686444e-03,  2.1353369e-03],\n",
       "        [-2.4114913e-04,  3.1374590e-03, -2.3560671e-03, ...,\n",
       "          1.2208496e-03,  8.2165597e-04,  2.2966755e-03],\n",
       "        [-8.8387221e-04,  4.0798043e-03, -2.2991828e-03, ...,\n",
       "          2.0573225e-03,  3.8575768e-04,  2.3447790e-03]],\n",
       "\n",
       "       [[-6.1928446e-04,  4.9484993e-04, -5.6126277e-04, ...,\n",
       "         -7.2491291e-04, -2.2428794e-04,  2.2621317e-04],\n",
       "        [-7.1319652e-04,  8.1486930e-04, -1.3201176e-03, ...,\n",
       "         -1.7750778e-03, -5.0871744e-04,  5.5352965e-04],\n",
       "        [-5.7613949e-04,  1.2409309e-03, -2.4206308e-03, ...,\n",
       "         -1.4859354e-03, -2.1326705e-04,  7.4670400e-04],\n",
       "        ...,\n",
       "        [-1.2711862e-04,  1.9776223e-03, -4.7891745e-03, ...,\n",
       "          1.9712042e-04, -1.0349764e-03,  3.4761478e-03],\n",
       "        [-3.3414538e-04,  2.9743023e-03, -4.2502414e-03, ...,\n",
       "          1.0772012e-03, -1.2850534e-03,  3.7022606e-03],\n",
       "        [-7.1002968e-04,  3.9405995e-03, -3.7222723e-03, ...,\n",
       "          2.0403259e-03, -1.6017137e-03,  3.7404390e-03]],\n",
       "\n",
       "       [[-6.1928446e-04,  4.9484993e-04, -5.6126277e-04, ...,\n",
       "         -7.2491291e-04, -2.2428794e-04,  2.2621317e-04],\n",
       "        [-1.1054222e-03,  1.0412378e-03, -4.4501267e-04, ...,\n",
       "         -1.1625390e-03, -7.1482122e-05,  4.5876802e-04],\n",
       "        [-9.2953135e-04,  1.0313655e-03, -5.4322061e-04, ...,\n",
       "         -1.9172468e-03,  7.0618873e-05,  1.2201570e-03],\n",
       "        ...,\n",
       "        [ 8.1508164e-04,  1.4466150e-03, -1.3507366e-03, ...,\n",
       "          5.9776972e-03, -7.8712864e-04,  2.8150317e-03],\n",
       "        [ 4.2795690e-04,  2.2973449e-03, -1.3774518e-03, ...,\n",
       "          6.5980135e-03, -1.0292277e-03,  2.6534263e-03],\n",
       "        [-8.6141663e-05,  3.1228345e-03, -1.4325599e-03, ...,\n",
       "          7.1504782e-03, -1.3078299e-03,  2.4548839e-03]]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for enc_sample, dec_sample in dataset.take(1): break\n",
    "model(enc_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- model의 최종 출력 tensor ```shape = (256, 13, 18001)```\n",
    "- 18001: Dense layer의 출력 차원수\n",
    "- 18001개의 단어 중 어느 단어의 확률이 가장 높을지를 모델링 해야하기 때문    \n",
    "<br/>   \n",
    "- 256: 배치 사이즈\n",
    "- ```dataset.take(1)```를 통해 1개 배치, 256개의 문장에서 가져온 것    \n",
    "<br/>    \n",
    "- 13: ```tf.keras.lauyers.LSTM(hidden_size, return_sequences=True)```로 호출한 LSTM layer에서 ```return_sequences=True```이정 한 부분\n",
    "- LSTM은 자신에게 입력된 시퀀스의 길이만큼 동일한 길이의 시퀀스를 출력\n",
    "- ```return_sequences=False``` 였다면, LSTM layer는 1개의 벡터만 출력   \n",
    "<br/>   \n",
    "- 문제점: 우리 모델은 입력 데이터의 스퀀스 길이를 모름\n",
    "- 데이터를 입력받으면서 13을 알게 됨\n",
    "- 데이터 셋의 max_len이 13으로 맞춰져 있었던 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  307456    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  5246976   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  1231025   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo multiple                  4096      \n",
      "=================================================================\n",
      "Total params: 15,182,257\n",
      "Trainable params: 15,180,209\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ouput shape를 정확하게 알려주지 않음\n",
    "- 우리 모델은 입력 시퀀스의 길이를 모르기 때문에 output shape를 특정할 수 없음\n",
    "- 하지만, 모델의 파라미터 사이즈는 측정 가능\n",
    "- 약 32million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "549/549 [==============================] - 44s 80ms/step - loss: 2.8287 - val_loss: 3.6007\n",
      "Epoch 2/10\n",
      "549/549 [==============================] - 45s 81ms/step - loss: 2.4637 - val_loss: 2.4204\n",
      "Epoch 3/10\n",
      "549/549 [==============================] - 45s 81ms/step - loss: 2.2899 - val_loss: 2.3212\n",
      "Epoch 4/10\n",
      "549/549 [==============================] - 42s 77ms/step - loss: 2.1348 - val_loss: 2.2520\n",
      "Epoch 5/10\n",
      "549/549 [==============================] - 40s 72ms/step - loss: 1.9836 - val_loss: 2.1935\n",
      "Epoch 6/10\n",
      "549/549 [==============================] - 40s 72ms/step - loss: 1.8329 - val_loss: 2.1498TA: 0s \n",
      "Epoch 7/10\n",
      "549/549 [==============================] - 40s 72ms/step - loss: 1.6891 - val_loss: 2.1138\n",
      "Epoch 8/10\n",
      "549/549 [==============================] - 40s 72ms/step - loss: 1.5554 - val_loss: 2.0941\n",
      "Epoch 9/10\n",
      "549/549 [==============================] - 40s 72ms/step - loss: 1.4386 - val_loss: 2.0850\n",
      "Epoch 10/10\n",
      "549/549 [==============================] - 40s 72ms/step - loss: 1.3399 - val_loss: 2.0889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f669c35b8d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "\n",
    "#Loss\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "model.fit(dataset, validation_data=val_dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(lyricist, tokenizer, init_sentence=\"<start> i love\", max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 일단 텐서로 변환합니다.\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 텍스트를 실제로 생성할때는 루프를 돌면서 단어 하나씩 생성해야 합니다. \n",
    "    while True:\n",
    "        predict = model(test_tensor)  # 입력받은 문장의 텐서를 입력합니다. \n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1]   # 우리 모델이 예측한 마지막 단어가 바로 새롭게 생성한 단어가 됩니다. \n",
    "\n",
    "        # 우리 모델이 새롭게 예측한 단어를 입력 문장의 뒤에 붙여 줍니다. \n",
    "        test_tensor = tf.concat([test_tensor, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "\n",
    "        # 우리 모델이 <END>를 예측했거나, max_len에 도달하지 않았다면  while 루프를 또 돌면서 다음 단어를 예측해야 합니다.\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # 생성된 tensor 안에 있는 word index를 tokenizer.index_word 사전을 통해 실제 단어로 하나씩 변환합니다. \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated   # 이것이 최종적으로 모델이 생성한 자연어 문장입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> sun is <unk> , moon is gone <end> '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> Sun\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Word=1600, batch 2, embedding size=256 ,lr=0.001 => overfitting    \n",
    "2. Word=1600, batch 2, embedding size=256, lr=0.05 => overfitting    \n",
    "<br/>   \n",
    "3. Word=1500, batch 2, embedding size=256, lr=0.001 => overfitting(Epoch 7_2.23~)\n",
    "4. Word=1500, batch 2, embedding size=256, lr=0.05 => overfitting(Epoch 5 3.128~)    \n",
    "<br/>   \n",
    "5. Word=1400, batch 2, embedding size=256, lr=0.001 => overfitting(Epoch 7 2.21~)    \n",
    "<br/>    \n",
    "6. Word=1200, batch 2, embedding size=256, lr=0.001 => overfitting(Epoch 7 2.12~)\n",
    "7. Word=1200, batch 1 (LSTM ~ Dense), embedding size=256, lr=0.001(Epoch 8 2.20~)   \n",
    "<br/>   \n",
    "```최종```\n",
    "8. Word=1200, batch 1 (LSTM1 ~ LSTM2), embedding size=256, lr=0.001    \n",
    "-> **val_loss: 2.0889**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정리\n",
    "- Batch Normalization를 활용하여 성능을 더 좋게 만들 수 있었음\n",
    "    - BN을 layer에 두 번 활용할 경우 Overfitting이 더 자주 일어남\n",
    "    - BN을 한 번은 LSTM_2과 Dense 레이어 사이에 넣어서 실행\n",
    "    - 나머지 한 번은 LSTM_1과 LSTM_2 레이어 사이에 넣어서 실행\n",
    "- 전체 단어의 개수는 1201개 이상 진행할 시 쉽게 Overfitting이 일어남\n",
    "    - Word 수를 줄일 수록 더 좋은 모형을 드러냄\n",
    "     \n",
    " <br/>   \n",
    " ```결론```\n",
    " - word = 1200, batch 1 (LSTM_1 ~ LSTM_2 layer), embedding size = 256, learning rate = 0.001\n",
    " - **val_loss: 2.0889**\n",
    " - 요구하는 val_loss 2.2 이하 맞춤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
