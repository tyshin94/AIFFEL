{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9-11. 프로젝트: 네이버 영화리뷰 감성분석 도전하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import urllib.request\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "\n",
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000, 3)\n",
      "(50000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loader \n",
    "- 데이터의 중복 제거\n",
    "- NaN 결측치 제거\n",
    "- 한국어 토크나이저로 토큰화\n",
    "- 불용어(Stopwords) 제거\n",
    "- 사전 **word_to_index** 구성\n",
    "- 텍스트 스트링을 사전 인덱스 스트링으로 변환\n",
    "- X_train, y_train, X_test, y_test, word_to_index 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def load_data(train_data, test_data, num_words=10000):\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how = 'any') \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "\n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "\n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(10000-4)\n",
    "    vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "\n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
    "\n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "\n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "    \n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## index_to_word 생성\n",
    "- **word_to_index**를 활용하여 새로운 **index_to_word** 생성\n",
    "- 그 외에 인덱스를 입려하면 단어로 리턴해주는 함수, 단어를 입력하면 인덱스로 리턴해주는 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델구성을 위한 데이터 분석 및 가공\n",
    "- 데이터셋 내 문장 길이 분포\n",
    "- 적절한 최대 문장 길이 지정\n",
    "- keras.preprocessing.sequence.pad_sequences 을 활용한 패딩 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  15.969376315021577\n",
      "문장길이 최대 :  116\n",
      "문장길이 표준편차 :  12.843535456326455\n",
      "pad_sequences maxlen :  41\n",
      "전체 문장의 0.9342988343341575%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(X_train) + list(X_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146182, 41)\n"
     ]
    }
   ],
   "source": [
    "X_train = keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49157, 41)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  validation set 구성 및 모델선정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**validation set 구성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146182"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126182, 41)\n",
      "(126182,)\n",
      "(20000, 41)\n",
      "(20000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 20000건 분리\n",
    "x_val = X_train[:20000]   \n",
    "y_val = y_train[:20000]\n",
    "\n",
    "# validation set을 제외한 나머지\n",
    "partial_X_train = X_train[20000:]  \n",
    "partial_y_train = y_train[20000:]\n",
    "\n",
    "print(partial_X_train.shape)\n",
    "print(partial_y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 선정**\n",
    "- 같은 파라미터로 3가지 모델을 학습\n",
    "    1. 1-D CNN\n",
    "    2. LSTM\n",
    "    3. GlobalMaxPooling1D\n",
    "- 이후에 가장 성능이 좋은 모델 선택 후 파라미터 튜닝을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세가지 모델을 평가할 때, 파라미터는 고정으로 사용\n",
    "vocab_size = len(index_to_word)\n",
    "word_vector_dim = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-D CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 300)         3000000   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 256)         537856    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 64)          114752    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 520       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,653,137\n",
      "Trainable params: 3,653,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CNN\n",
    "\n",
    "CNN_model = keras.Sequential(name=\"CNN\")\n",
    "CNN_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "CNN_model.add(keras.layers.Conv1D(256, 7, activation='relu'))\n",
    "CNN_model.add(keras.layers.MaxPooling1D(5))\n",
    "CNN_model.add(keras.layers.Conv1D(64, 7, activation='relu'))\n",
    "CNN_model.add(keras.layers.GlobalMaxPooling1D())\n",
    "CNN_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "CNN_model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "CNN_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 300)         3000000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 9888      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,009,969\n",
      "Trainable params: 3,009,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM\n",
    "\n",
    "LSTM_model = keras.Sequential(name=\"LSTM\")\n",
    "LSTM_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "LSTM_model.add(keras.layers.LSTM(8, dropout=0.7))\n",
    "LSTM_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "LSTM_model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "LSTM_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GlobalMaxPooling1D**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GMP\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 300)         3000000   \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 2408      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,002,417\n",
      "Trainable params: 3,002,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GlobalMaxPooling1D\n",
    "\n",
    "GMP_model = keras.Sequential(name=\"GMP\")\n",
    "GMP_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "GMP_model.add(keras.layers.GlobalMaxPooling1D())\n",
    "GMP_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "GMP_model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "GMP_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3가지 모델을 같은 조건에서 학습 후 결과 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CNN', 'LSTM', 'GMP']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lst = [CNN_model.name, LSTM_model.name, GMP_model.name]\n",
    "model_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Start fitting CNN ...\n",
      "Epoch 1/20\n",
      "247/247 [==============================] - 16s 64ms/step - loss: 0.4036 - accuracy: 0.8061 - val_loss: 0.3319 - val_accuracy: 0.8539\n",
      "Epoch 2/20\n",
      "247/247 [==============================] - 10s 40ms/step - loss: 0.2773 - accuracy: 0.8850 - val_loss: 0.3198 - val_accuracy: 0.8619\n",
      "Epoch 3/20\n",
      "247/247 [==============================] - 10s 41ms/step - loss: 0.1862 - accuracy: 0.9271 - val_loss: 0.3631 - val_accuracy: 0.8523\n",
      "Epoch 4/20\n",
      "247/247 [==============================] - 10s 40ms/step - loss: 0.0999 - accuracy: 0.9648 - val_loss: 0.4649 - val_accuracy: 0.8510\n",
      "Epoch 5/20\n",
      "247/247 [==============================] - 9s 38ms/step - loss: 0.0567 - accuracy: 0.9803 - val_loss: 0.6056 - val_accuracy: 0.8453\n",
      "Epoch 6/20\n",
      "247/247 [==============================] - 9s 38ms/step - loss: 0.0379 - accuracy: 0.9867 - val_loss: 0.7201 - val_accuracy: 0.8442\n",
      "Epoch 7/20\n",
      "247/247 [==============================] - 9s 37ms/step - loss: 0.0358 - accuracy: 0.9872 - val_loss: 0.7347 - val_accuracy: 0.8416\n",
      "Epoch 8/20\n",
      "247/247 [==============================] - 9s 37ms/step - loss: 0.0345 - accuracy: 0.9872 - val_loss: 0.8236 - val_accuracy: 0.8496\n",
      "Epoch 9/20\n",
      "247/247 [==============================] - 9s 38ms/step - loss: 0.0255 - accuracy: 0.9906 - val_loss: 0.9001 - val_accuracy: 0.8444\n",
      "Epoch 10/20\n",
      "247/247 [==============================] - 9s 38ms/step - loss: 0.0221 - accuracy: 0.9920 - val_loss: 0.8962 - val_accuracy: 0.8461\n",
      "Epoch 11/20\n",
      "247/247 [==============================] - 10s 39ms/step - loss: 0.0196 - accuracy: 0.9925 - val_loss: 0.9886 - val_accuracy: 0.8413\n",
      "Epoch 12/20\n",
      "247/247 [==============================] - 10s 39ms/step - loss: 0.0178 - accuracy: 0.9930 - val_loss: 1.0180 - val_accuracy: 0.8446\n",
      "Epoch 13/20\n",
      "247/247 [==============================] - 10s 39ms/step - loss: 0.0150 - accuracy: 0.9940 - val_loss: 1.0246 - val_accuracy: 0.8406\n",
      "Epoch 14/20\n",
      "247/247 [==============================] - 9s 38ms/step - loss: 0.0161 - accuracy: 0.9938 - val_loss: 1.0169 - val_accuracy: 0.8417\n",
      "Epoch 15/20\n",
      "247/247 [==============================] - 9s 38ms/step - loss: 0.0168 - accuracy: 0.9936 - val_loss: 1.0556 - val_accuracy: 0.8411\n",
      "Epoch 16/20\n",
      "247/247 [==============================] - 9s 38ms/step - loss: 0.0137 - accuracy: 0.9945 - val_loss: 1.1306 - val_accuracy: 0.8432\n",
      "Epoch 17/20\n",
      "247/247 [==============================] - 9s 38ms/step - loss: 0.0133 - accuracy: 0.9947 - val_loss: 1.1347 - val_accuracy: 0.8436\n",
      "Epoch 18/20\n",
      "247/247 [==============================] - 9s 38ms/step - loss: 0.0132 - accuracy: 0.9949 - val_loss: 1.0962 - val_accuracy: 0.8431\n",
      "Epoch 19/20\n",
      "247/247 [==============================] - 9s 38ms/step - loss: 0.0114 - accuracy: 0.9957 - val_loss: 1.1200 - val_accuracy: 0.8440\n",
      "Epoch 20/20\n",
      "247/247 [==============================] - 9s 38ms/step - loss: 0.0106 - accuracy: 0.9957 - val_loss: 1.1869 - val_accuracy: 0.8410\n",
      "Start evaluating CNN ...\n",
      "1537/1537 - 4s - loss: 1.2446 - accuracy: 0.8366\n",
      "----------------------------------------\n",
      "Start fitting LSTM ...\n",
      "Epoch 1/20\n",
      "247/247 [==============================] - 8s 31ms/step - loss: 0.6046 - accuracy: 0.6638 - val_loss: 0.5243 - val_accuracy: 0.7757\n",
      "Epoch 2/20\n",
      "247/247 [==============================] - 7s 30ms/step - loss: 0.4730 - accuracy: 0.8062 - val_loss: 0.4131 - val_accuracy: 0.8280\n",
      "Epoch 3/20\n",
      "247/247 [==============================] - 7s 30ms/step - loss: 0.3951 - accuracy: 0.8371 - val_loss: 0.3871 - val_accuracy: 0.8440\n",
      "Epoch 4/20\n",
      "247/247 [==============================] - 7s 30ms/step - loss: 0.3565 - accuracy: 0.8558 - val_loss: 0.3612 - val_accuracy: 0.8482\n",
      "Epoch 5/20\n",
      "247/247 [==============================] - 7s 30ms/step - loss: 0.3274 - accuracy: 0.8673 - val_loss: 0.3457 - val_accuracy: 0.8529\n",
      "Epoch 6/20\n",
      "247/247 [==============================] - 7s 30ms/step - loss: 0.3057 - accuracy: 0.8755 - val_loss: 0.3419 - val_accuracy: 0.8540\n",
      "Epoch 7/20\n",
      "247/247 [==============================] - 7s 30ms/step - loss: 0.2904 - accuracy: 0.8826 - val_loss: 0.3425 - val_accuracy: 0.8533\n",
      "Epoch 8/20\n",
      "247/247 [==============================] - 7s 29ms/step - loss: 0.2747 - accuracy: 0.8876 - val_loss: 0.3400 - val_accuracy: 0.8550\n",
      "Epoch 9/20\n",
      "247/247 [==============================] - 7s 29ms/step - loss: 0.2620 - accuracy: 0.8926 - val_loss: 0.3450 - val_accuracy: 0.8568\n",
      "Epoch 10/20\n",
      "247/247 [==============================] - 7s 29ms/step - loss: 0.2501 - accuracy: 0.8971 - val_loss: 0.3510 - val_accuracy: 0.8545\n",
      "Epoch 11/20\n",
      "247/247 [==============================] - 7s 30ms/step - loss: 0.2414 - accuracy: 0.9013 - val_loss: 0.3676 - val_accuracy: 0.8545\n",
      "Epoch 12/20\n",
      "247/247 [==============================] - 7s 30ms/step - loss: 0.2310 - accuracy: 0.9046 - val_loss: 0.3682 - val_accuracy: 0.8536\n",
      "Epoch 13/20\n",
      "247/247 [==============================] - 7s 30ms/step - loss: 0.2223 - accuracy: 0.9094 - val_loss: 0.3743 - val_accuracy: 0.8541\n",
      "Epoch 14/20\n",
      "247/247 [==============================] - 7s 30ms/step - loss: 0.2157 - accuracy: 0.9117 - val_loss: 0.3872 - val_accuracy: 0.8529\n",
      "Epoch 15/20\n",
      "247/247 [==============================] - 7s 30ms/step - loss: 0.2086 - accuracy: 0.9149 - val_loss: 0.3961 - val_accuracy: 0.8501\n",
      "Epoch 16/20\n",
      "247/247 [==============================] - 7s 29ms/step - loss: 0.2026 - accuracy: 0.9179 - val_loss: 0.4003 - val_accuracy: 0.8514\n",
      "Epoch 17/20\n",
      "247/247 [==============================] - 7s 29ms/step - loss: 0.1975 - accuracy: 0.9202 - val_loss: 0.4146 - val_accuracy: 0.8518\n",
      "Epoch 18/20\n",
      "247/247 [==============================] - 7s 29ms/step - loss: 0.1922 - accuracy: 0.9227 - val_loss: 0.4144 - val_accuracy: 0.8519\n",
      "Epoch 19/20\n",
      "247/247 [==============================] - 7s 29ms/step - loss: 0.1861 - accuracy: 0.9253 - val_loss: 0.4301 - val_accuracy: 0.8511\n",
      "Epoch 20/20\n",
      "247/247 [==============================] - 7s 29ms/step - loss: 0.1827 - accuracy: 0.9261 - val_loss: 0.4168 - val_accuracy: 0.8516\n",
      "Start evaluating LSTM ...\n",
      "1537/1537 - 2s - loss: 0.4139 - accuracy: 0.8502\n",
      "----------------------------------------\n",
      "Start fitting GMP ...\n",
      "Epoch 1/20\n",
      "247/247 [==============================] - 7s 28ms/step - loss: 0.4576 - accuracy: 0.8092 - val_loss: 0.3423 - val_accuracy: 0.8503\n",
      "Epoch 2/20\n",
      "247/247 [==============================] - 7s 27ms/step - loss: 0.3075 - accuracy: 0.8708 - val_loss: 0.3305 - val_accuracy: 0.8563\n",
      "Epoch 3/20\n",
      "247/247 [==============================] - 7s 27ms/step - loss: 0.2599 - accuracy: 0.8944 - val_loss: 0.3384 - val_accuracy: 0.8566\n",
      "Epoch 4/20\n",
      "247/247 [==============================] - 7s 27ms/step - loss: 0.2167 - accuracy: 0.9161 - val_loss: 0.3524 - val_accuracy: 0.8565\n",
      "Epoch 5/20\n",
      "247/247 [==============================] - 7s 27ms/step - loss: 0.1722 - accuracy: 0.9377 - val_loss: 0.3791 - val_accuracy: 0.8526\n",
      "Epoch 6/20\n",
      "247/247 [==============================] - 7s 27ms/step - loss: 0.1266 - accuracy: 0.9586 - val_loss: 0.4155 - val_accuracy: 0.8515\n",
      "Epoch 7/20\n",
      "247/247 [==============================] - 7s 27ms/step - loss: 0.0866 - accuracy: 0.9751 - val_loss: 0.4595 - val_accuracy: 0.8482\n",
      "Epoch 8/20\n",
      "247/247 [==============================] - 7s 27ms/step - loss: 0.0562 - accuracy: 0.9858 - val_loss: 0.5025 - val_accuracy: 0.8482\n",
      "Epoch 9/20\n",
      "247/247 [==============================] - 7s 27ms/step - loss: 0.0368 - accuracy: 0.9913 - val_loss: 0.5482 - val_accuracy: 0.8460\n",
      "Epoch 10/20\n",
      "247/247 [==============================] - 7s 27ms/step - loss: 0.0253 - accuracy: 0.9938 - val_loss: 0.5865 - val_accuracy: 0.8442\n",
      "Epoch 11/20\n",
      "247/247 [==============================] - 7s 27ms/step - loss: 0.0184 - accuracy: 0.9952 - val_loss: 0.6189 - val_accuracy: 0.8427\n",
      "Epoch 12/20\n",
      "247/247 [==============================] - 7s 27ms/step - loss: 0.0143 - accuracy: 0.9960 - val_loss: 0.6513 - val_accuracy: 0.8438\n",
      "Epoch 13/20\n",
      "247/247 [==============================] - 7s 27ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.6829 - val_accuracy: 0.8414\n",
      "Epoch 14/20\n",
      "247/247 [==============================] - 7s 27ms/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 0.7014 - val_accuracy: 0.8431\n",
      "Epoch 15/20\n",
      "247/247 [==============================] - 7s 27ms/step - loss: 0.0093 - accuracy: 0.9966 - val_loss: 0.7263 - val_accuracy: 0.8429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "247/247 [==============================] - 7s 27ms/step - loss: 0.0086 - accuracy: 0.9964 - val_loss: 0.7486 - val_accuracy: 0.8424\n",
      "Epoch 17/20\n",
      "247/247 [==============================] - 7s 27ms/step - loss: 0.0077 - accuracy: 0.9967 - val_loss: 0.7700 - val_accuracy: 0.8425\n",
      "Epoch 18/20\n",
      "247/247 [==============================] - 7s 27ms/step - loss: 0.0073 - accuracy: 0.9968 - val_loss: 0.7909 - val_accuracy: 0.8424\n",
      "Epoch 19/20\n",
      "247/247 [==============================] - 7s 27ms/step - loss: 0.0069 - accuracy: 0.9969 - val_loss: 0.8027 - val_accuracy: 0.8440\n",
      "Epoch 20/20\n",
      "247/247 [==============================] - 7s 27ms/step - loss: 0.0068 - accuracy: 0.9969 - val_loss: 0.8206 - val_accuracy: 0.8402\n",
      "Start evaluating GMP ...\n",
      "1537/1537 - 2s - loss: 0.8352 - accuracy: 0.8380\n"
     ]
    }
   ],
   "source": [
    "model_result = {}\n",
    "\n",
    "for model_name in model_lst:\n",
    "    \n",
    "    if model_name == \"CNN\":\n",
    "        model = CNN_model\n",
    "    elif model_name == \"LSTM\":\n",
    "        model = LSTM_model\n",
    "    else :\n",
    "        model = GMP_model\n",
    "    \n",
    "    print('-'*40)\n",
    "    print(\"Start fitting {} ...\".format(model_name))\n",
    "    model.compile(optimizer='Adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    epochs=20\n",
    "\n",
    "    history = model.fit(partial_X_train,\n",
    "                        partial_y_train,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=512,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        verbose=1)\n",
    "    \n",
    "    \n",
    "    print(\"Start evaluating {} ...\".format(model_name))\n",
    "    results = model.evaluate(X_test,  y_test, verbose=2)\n",
    "    model_result[model_name] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM \t 0.8501942753791809\n",
      "GMP \t 0.8379681706428528\n",
      "CNN \t 0.8366255164146423\n"
     ]
    }
   ],
   "source": [
    "for name, [_, acc] in sorted(model_result.items(), key=lambda x : x[1][1], reverse=True) :\n",
    "    print(name,'\\t',acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 훈련\n",
    "- 위 모델 중 **LTSM**의 성능이 가장 좋았음\n",
    "- 모델 훈련하기 전에 성능을 올릴 수 있는 최적의 하이퍼파라미터 값을 찾아봄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**최적의 모델 만들기**\n",
    "- LSTM모델 앞에 CNN을 추가도 해보았고, LSTM을 추가도 해보았다.\n",
    "    - CNN의 경우는 추가를 하면 성능이 더 나빴다.\n",
    "    - LSTM층을 하나 더 추가할 경우 결과는 크게 달라지지 않았지만 학습 곡선이 다르게 나타나는 것을 알 수 있었다.\n",
    "- 간단하게 LSTM 레이어 하나만을 사용해서 하이퍼파라미터를 튜닝해보도록 하였다.\n",
    "    - word_vector_dim 을 늘려가면서 성능이 점점 더 좋아지는 것을 알 수 있었다.\n",
    "        - 1000\n",
    "    - LSTM 레이어의 벡터 차원수를 기존에 8에서 128까지 늘렸다.\n",
    "    - input dimension이 1000개에 반해 128개의 차원은 여전히 부족하지 않을까?\n",
    "    - Overfitting이 자주 발생하여서 LSTM의 인자로 Dropout도 추가하였다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 1000)        10000000  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               578048    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 1032      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 10,579,089\n",
      "Trainable params: 10,579,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "word_vector_dim = 1000  # 워드 벡터의 차원수\n",
    "\n",
    "'''\n",
    "# LSTM 기존 모델\n",
    " \n",
    "word_vector_dim = 300 \n",
    "\n",
    "LSTM_model = keras.Sequential(name=\"LSTM\")\n",
    "LSTM_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "LSTM_model.add(keras.layers.LSTM(8, dropout=0.7))\n",
    "LSTM_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "LSTM_model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "'''\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "# CNN을 추가했을 때\n",
    "# model.add(keras.layers.Conv1D(8, 7, activation='relu'))\n",
    "# model.add(keras.layers.MaxPooling1D())\n",
    "# LSTM 레이어를 두개로 학습했을 때\n",
    "# model.add(keras.layers.LSTM(256, dropout=0.7, return_sequences=True))\n",
    "model.add(keras.layers.LSTM(128, dropout=0.7))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 이진분류\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이전에 20번 epoch을 돌리는 동안 **validation loss**값이 오르는 것을 확인 **(Overfitting 발생)** \n",
    "\n",
    "- 그 결과, **callback의 EarlyStopping**을 사용하였고 최적의 모델을 저장하기 위해서 **ModelCheckpoint**를 사용하였다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "model_check = tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model compile**\n",
    "- optimizer에서 사용하는 Adam에도 learning rate를 조절\n",
    "- 이전에 세가지 모델을 학습시켜보았을 때 여러번 학습이 진행되기 전에 Overfitting이 발생하였기 때문에 학습률을 낮춤\n",
    "- 추가적으로 배치사이즈도 더 작게 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "986/986 [==============================] - ETA: 0s - loss: 0.4486 - accuracy: 0.7686\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.85000, saving model to model.h5\n",
      "986/986 [==============================] - 75s 76ms/step - loss: 0.4486 - accuracy: 0.7686 - val_loss: 0.3425 - val_accuracy: 0.8500\n",
      "Epoch 2/20\n",
      "986/986 [==============================] - ETA: 0s - loss: 0.3265 - accuracy: 0.8591\n",
      "Epoch 00002: val_accuracy improved from 0.85000 to 0.85920, saving model to model.h5\n",
      "986/986 [==============================] - 75s 76ms/step - loss: 0.3265 - accuracy: 0.8591 - val_loss: 0.3273 - val_accuracy: 0.8592\n",
      "Epoch 3/20\n",
      "986/986 [==============================] - ETA: 0s - loss: 0.2896 - accuracy: 0.8760\n",
      "Epoch 00003: val_accuracy improved from 0.85920 to 0.86510, saving model to model.h5\n",
      "986/986 [==============================] - 74s 75ms/step - loss: 0.2896 - accuracy: 0.8760 - val_loss: 0.3168 - val_accuracy: 0.8651\n",
      "Epoch 4/20\n",
      "986/986 [==============================] - ETA: 0s - loss: 0.2640 - accuracy: 0.8890\n",
      "Epoch 00004: val_accuracy improved from 0.86510 to 0.86725, saving model to model.h5\n",
      "986/986 [==============================] - 75s 76ms/step - loss: 0.2640 - accuracy: 0.8890 - val_loss: 0.3193 - val_accuracy: 0.8673\n",
      "Epoch 5/20\n",
      "986/986 [==============================] - ETA: 0s - loss: 0.2433 - accuracy: 0.8987\n",
      "Epoch 00005: val_accuracy did not improve from 0.86725\n",
      "986/986 [==============================] - 74s 75ms/step - loss: 0.2433 - accuracy: 0.8987 - val_loss: 0.3296 - val_accuracy: 0.8660\n",
      "Epoch 6/20\n",
      "986/986 [==============================] - ETA: 0s - loss: 0.2252 - accuracy: 0.9070\n",
      "Epoch 00006: val_accuracy did not improve from 0.86725\n",
      "986/986 [==============================] - 74s 75ms/step - loss: 0.2252 - accuracy: 0.9070 - val_loss: 0.3389 - val_accuracy: 0.8638\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20\n",
    "history = model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=128,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1,\n",
    "                   callbacks=[early_stopping, model_check])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 4s - loss: 0.3462 - accuracy: 0.8601\n",
      "[0.34623509645462036, 0.8601012825965881]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss, Accuracy 그래프 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# 빨간 실선으로 표시\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "# 파란 실선으로 표시\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습된 Embedding 레이어 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1000)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 학습한 Embedding 파라미터를 파일에 써서 저장\n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim)) # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀작성\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록\n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- gensim을 사용해서 학습시킨 word2vector를 사용해서 대박이라는 단어와 연관성이 있는 단어들을 뽑아 봄\n",
    "- 영화 리뷰라고 생각해보았을 때, 긍정적인 평가들이 나오는 것을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['대박']\n",
    "# vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('괜춘', 0.5811702013015747),\n",
       " ('올려야', 0.5804870128631592),\n",
       " ('뗄', 0.5663620233535767),\n",
       " ('담백', 0.5601297616958618),\n",
       " ('감독판', 0.5591539144515991),\n",
       " ('독도', 0.5563544631004333),\n",
       " ('놀라웠', 0.551439642906189),\n",
       " ('구할', 0.5499293804168701),\n",
       " ('각지', 0.5498082041740417),\n",
       " ('미남', 0.5493574142456055)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"대박\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한국어 Word2Vec 임베딩 활용하여 성능 개선\n",
    "- 한국어 Word2Vec은 다음 경로에서 구할 수 있습니다.\n",
    "- https://github.com/Kyubyong/wordvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word2vec.txt', 'ratings_test.txt', 'ko.tsv', 'ko.bin', 'ratings_train.txt']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/home/aiffel0042/aiffel/sentiment_classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aiffel0042/aiffel/sentiment_classification/ko.tsv'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv('HOME')+'/aiffel/sentiment_classification/ko.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/ko.bin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**기존의 코드**    \n",
    "- from gensim.models.keyedvectors import Word2VecKeyedVectors     \n",
    "- word2vec = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**bin** 파일로 저장되어 있는 **word2vec** 불러오기 위해 아래와 같이 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "word2vec = Word2Vec.load(word2vec_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.12250227, -0.26166117,  0.1601894 ,  0.24988233, -0.19694664,\n",
       "        0.20742898,  0.23358916, -0.08032743,  0.07419734,  0.28976992,\n",
       "        0.05920417, -0.24217431,  0.42650384,  0.37083197,  0.01488842,\n",
       "       -0.15399031,  0.21594983,  0.16782928,  0.04716487, -0.3933347 ,\n",
       "        0.06105555, -0.13588727, -0.0257909 , -0.06074918,  0.04168789,\n",
       "        0.34588724,  0.24693313, -0.05122459,  0.16371667,  0.05747311,\n",
       "       -0.12627307, -0.16464052, -0.29741055,  0.17121391, -0.24180788,\n",
       "       -0.28056645, -0.06616814,  0.15681611,  0.20206362, -0.1660444 ,\n",
       "        0.00203782, -0.2563252 , -0.24074501, -0.63730514,  0.35244125,\n",
       "        0.05436644, -0.14913762, -0.06556495, -0.05610788,  0.11254067,\n",
       "       -0.09251513, -0.28059378,  0.07197419,  0.11595767,  0.15117767,\n",
       "       -0.00541334, -0.128903  ,  0.04034068, -0.22690742,  0.00775241,\n",
       "        0.16708778,  0.10937496, -0.17221814,  0.04758313,  0.321897  ,\n",
       "        0.0646909 ,  0.292136  , -0.07984147,  0.09785581,  0.181296  ,\n",
       "        0.17631158,  0.01031382, -0.43260768,  0.01173338,  0.03490037,\n",
       "       -0.0076601 , -0.06428192, -0.2924691 ,  0.24474835,  0.07950445,\n",
       "       -0.09601387, -0.34834263, -0.17978796,  0.23437631, -0.15391289,\n",
       "        0.01297345, -0.04877474, -0.22579618, -0.06827989, -0.266499  ,\n",
       "       -0.18218975, -0.45568773, -0.19330987,  0.09304521,  0.08007847,\n",
       "       -0.08579313, -0.01735996, -0.20058121, -0.11037695, -0.04257905,\n",
       "       -0.01491661,  0.24702635, -0.06080532,  0.07469252,  0.02070692,\n",
       "        0.20998064, -0.12500262, -0.16058917,  0.13576448, -0.01957137,\n",
       "       -0.03530353,  0.02538178,  0.02707971,  0.02211284,  0.4662458 ,\n",
       "       -0.13323712, -0.31756285, -0.26687905, -0.2932379 ,  0.16787444,\n",
       "       -0.00277177,  0.11576287, -0.0071318 ,  0.04130382, -0.0535576 ,\n",
       "        0.5331611 ,  0.15177174,  0.308193  ,  0.12067769, -0.11636538,\n",
       "       -0.16276449, -0.1450912 , -0.07153927,  0.00982432,  0.16283946,\n",
       "        0.16073047, -0.30461156,  0.06590325,  0.18986021,  0.22578666,\n",
       "       -0.10132927,  0.1319676 , -0.28178945,  0.03667555, -0.02295887,\n",
       "       -0.15407115, -0.3441792 , -0.1218596 , -0.3528504 , -0.14319238,\n",
       "       -0.3211591 ,  0.14814556, -0.10278759,  0.23421551,  0.08331902,\n",
       "        0.00759588,  0.39796677, -0.13322656, -0.33425966, -0.2488725 ,\n",
       "        0.22625662, -0.01530029, -0.1754215 ,  0.06301978, -0.09565204,\n",
       "        0.22803056, -0.09959741, -0.08168349,  0.02098079,  0.09322228,\n",
       "       -0.00068385, -0.18893392,  0.2519263 ,  0.05090755,  0.2681667 ,\n",
       "        0.34096426, -0.18010454,  0.16246942,  0.01820518, -0.0705201 ,\n",
       "        0.08623672, -0.01494653, -0.21275468, -0.0316746 ,  0.26614192,\n",
       "        0.02781401,  0.1385179 ,  0.38353992, -0.08111849,  0.10542663,\n",
       "       -0.19549905,  0.01497585,  0.05798322,  0.02531051, -0.04150281,\n",
       "       -0.12611519, -0.05583593, -0.07526224, -0.08963452,  0.0068798 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = word2vec['대박']\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 불러온 **word2vec** 사용하여 **embedding_matrix** 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  \n",
      "/home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "word_vector_dim = 200\n",
    "\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위에서 만든 임베딩을 여기서 학습하는데 활용\n",
    "- 모델은 위에서 사용한것과 동일하게 LSTM을 사용하였고 LSTM 레이어의 차원도 128로 설정\n",
    "- 여기서 Embedding 레이어에 embedding_matrix로 초기화를 해주었기 때문에 **word_vector_dim**과 같은 경우는 **기존에 초기화 되어있는 임베딩의 차원인 200**으로 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 41, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               467968    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 2056      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,470,033\n",
      "Trainable params: 2,470,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000\n",
    "word_vector_dim = 200\n",
    "\n",
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix), \n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "\n",
    "model.add(keras.layers.LSTM(256))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "985/986 [============================>.] - ETA: 0s - loss: 0.4871 - accuracy: 0.7378\n",
      "Epoch 00001: val_accuracy did not improve from 0.86725\n",
      "986/986 [==============================] - 19s 19ms/step - loss: 0.4870 - accuracy: 0.7379 - val_loss: 0.3536 - val_accuracy: 0.8467\n",
      "Epoch 2/20\n",
      "984/986 [============================>.] - ETA: 0s - loss: 0.3192 - accuracy: 0.8627\n",
      "Epoch 00002: val_accuracy did not improve from 0.86725\n",
      "986/986 [==============================] - 18s 19ms/step - loss: 0.3192 - accuracy: 0.8627 - val_loss: 0.3179 - val_accuracy: 0.8635\n",
      "Epoch 3/20\n",
      "985/986 [============================>.] - ETA: 0s - loss: 0.2749 - accuracy: 0.8846\n",
      "Epoch 00003: val_accuracy did not improve from 0.86725\n",
      "986/986 [==============================] - 19s 19ms/step - loss: 0.2749 - accuracy: 0.8846 - val_loss: 0.3142 - val_accuracy: 0.8663\n",
      "Epoch 4/20\n",
      "985/986 [============================>.] - ETA: 0s - loss: 0.2410 - accuracy: 0.9010\n",
      "Epoch 00004: val_accuracy improved from 0.86725 to 0.86855, saving model to model.h5\n",
      "986/986 [==============================] - 21s 21ms/step - loss: 0.2410 - accuracy: 0.9010 - val_loss: 0.3113 - val_accuracy: 0.8686\n",
      "Epoch 5/20\n",
      "986/986 [==============================] - ETA: 0s - loss: 0.2097 - accuracy: 0.9153\n",
      "Epoch 00005: val_accuracy did not improve from 0.86855\n",
      "986/986 [==============================] - 18s 19ms/step - loss: 0.2097 - accuracy: 0.9153 - val_loss: 0.3255 - val_accuracy: 0.8652\n",
      "Epoch 6/20\n",
      "985/986 [============================>.] - ETA: 0s - loss: 0.1749 - accuracy: 0.9317\n",
      "Epoch 00006: val_accuracy did not improve from 0.86855\n",
      "986/986 [==============================] - 18s 19ms/step - loss: 0.1749 - accuracy: 0.9317 - val_loss: 0.3654 - val_accuracy: 0.8655\n",
      "Epoch 7/20\n",
      "986/986 [==============================] - ETA: 0s - loss: 0.1445 - accuracy: 0.9451\n",
      "Epoch 00007: val_accuracy did not improve from 0.86855\n",
      "986/986 [==============================] - 19s 19ms/step - loss: 0.1445 - accuracy: 0.9451 - val_loss: 0.3825 - val_accuracy: 0.8642\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20\n",
    "\n",
    "history = model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=128,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1,\n",
    "                   callbacks=[early_stopping, model_check])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 3s - loss: 0.3878 - accuracy: 0.8625\n",
      "[0.38776037096977234, 0.8625018000602722]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **validation accurary**가 **0.002** 증가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys())\n",
    "\n",
    "# 시각화를 시도한다.\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# 빨간 실선으로 표시\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "# 파란 실선으로 표시\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "- 세 가지 모델을 사용\n",
    "    1. **1D CNN** : 0.8413\n",
    "    2. **LSTM** : 0.8424\n",
    "    3. **GlobalMaxPooling1D** : 0.8402   \n",
    "<br/>    \n",
    "- 그 중에서 제일 좋은 **LSTM**으로 선택 -> 모델 구조 찾기\n",
    "    - 하이퍼 파라미터를 튜닝하기 전, 모델 구조에 대해 파악\n",
    "        1. CNN 1D -> LSTM\n",
    "        2. LSTM -> LSTM\n",
    "        3. LSTM 단일 레이어    \n",
    "    - 하지만 CNN을 추가한 경우 생각보다 점수가 낮게 나오고 LSTM 레이어를 두개를 사용해도 성능은 나아지지 않음    \n",
    "<br/>      \n",
    "- 하이퍼 파라미터 설정\n",
    "    - word_vector_dim = 1000\n",
    "    - LSTM 레이어의 차원 수 = 128, dropout = 0.7 적용\n",
    "    - Adam optimizer의 learning rate = 0.0005\n",
    "    - batch_size = 128  \n",
    "<br/>    \n",
    "- Callback 함수 사용\n",
    "    - EearlyStopping\n",
    "    - Checkpoint    \n",
    "<br/>    \n",
    "     \n",
    "**정확도** 0.84 -> 0.86\n",
    "- 약 2퍼센트 향상"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
